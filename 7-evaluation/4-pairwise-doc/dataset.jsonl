{"inputs": {"files": {"prompts.py": "QA_SYSTEM_PROMPT = \"\"\"\nYou are an assistant that helps to form nice and human understandable answers.\nThe information part contains the provided information that you must use to construct an answer.\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\nHere is an example:\n\nQuestion: How many songs do you have by James Brown?\nContext:[20]\nHelpful Answer: We have 20 songs by James Brown.\n\nFollow this example when generating answers.\nIf the provided information is empty, say that you don't know the answer.\nYou will have the full message history to help you answer the question, if you need more information, ask the user for it.\n\"\"\"\n\nSQL_SYSTEM_PROMPT = \"\"\"\nTask: Generate SQL statement to query a database.\nInstructions:\nUse only the provided relationship types and properties in the schema.\nDo not use any other relationship types or properties that are not provided.\nNote: Do not include any explanations or apologies in your responses.\nDo not respond to any questions that might ask anything else than for you to construct a SQL statement.\nDo not include any text except the generated SQL statement.\nYou will have the full message history to help you answer the question, if you dont need to generate a sql query, just generate a sql query that will return an empty result.\n\"\"\"", "utils.py": "import sqlite3\n\nimport requests\nfrom langchain_community.utilities.sql_database import SQLDatabase\nfrom sqlalchemy import create_engine, inspect\nfrom sqlalchemy.pool import StaticPool\n\n\n# fetch the chinook database from github and create an in-memory database\ndef get_engine_for_chinook_db():\n    \"\"\"Pull sql file, populate in-memory database, and create engine.\"\"\"\n    url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\"\n    response = requests.get(url, timeout=10)\n    sql_script = response.text\n\n    connection = sqlite3.connect(\":memory:\", check_same_thread=False)\n    connection.executescript(sql_script)\n    return create_engine(\n        \"sqlite://\",\n        creator=lambda: connection,\n        poolclass=StaticPool,\n        connect_args={\"check_same_thread\": False},\n    )\n\n\ndef get_db_table_names():\n    \"\"\"Get list of all table names in the database.\"\"\"\n    engine = get_engine_for_chinook_db()\n    db = SQLDatabase(engine)\n    return db.get_usable_table_names()\n\n\ndef get_detailed_table_info():\n    \"\"\"Get detailed information for each table including schema, keys, and sample data.\"\"\"\n    engine = get_engine_for_chinook_db()\n    db = SQLDatabase(engine)\n    inspector = inspect(engine)\n    table_names = db.get_usable_table_names()\n\n    detailed_info = {}\n\n    for table_name in table_names:\n        table_info = {\n            \"columns\": [],\n            \"primary_key\": None,\n            \"foreign_keys\": [],\n            \"sample_data\": [],\n        }\n\n        try:\n            columns = inspector.get_columns(table_name)\n            for column in columns:\n                table_info[\"columns\"].append(\n                    {\n                        \"name\": column[\"name\"],\n                        \"type\": str(column[\"type\"]),\n                        \"nullable\": column.get(\"nullable\", \"unknown\"),\n                    }\n                )\n\n            pk = inspector.get_pk_constraint(table_name)\n            if pk[\"constrained_columns\"]:\n                table_info[\"primary_key\"] = pk[\"constrained_columns\"]\n\n            fks = inspector.get_foreign_keys(table_name)\n            for fk in fks:\n                table_info[\"foreign_keys\"].append(\n                    {\n                        \"columns\": fk[\"constrained_columns\"],\n                        \"referred_table\": fk[\"referred_table\"],\n                        \"referred_columns\": fk[\"referred_columns\"],\n                    }\n                )\n\n        except Exception as e:\n            table_info[\"error\"] = str(e)\n\n        try:\n            sample_query = f\"SELECT * FROM {table_name} LIMIT 3\"\n            sample_result = db.run(sample_query)\n            table_info[\"sample_data\"] = sample_result\n        except Exception as e:\n            table_info[\"sample_data_error\"] = str(e)\n\n        detailed_info[table_name] = table_info\n\n    return detailed_info\n\n\ndef get_schema_overview():\n    \"\"\"Get a concise overview of all table schemas.\"\"\"\n    engine = get_engine_for_chinook_db()\n    db = SQLDatabase(engine)\n    inspector = inspect(engine)\n    table_names = db.get_usable_table_names()\n\n    schema_overview = {}\n\n    for table_name in table_names:\n        try:\n            columns = inspector.get_columns(table_name)\n            schema_overview[table_name] = [\n                {\"name\": col[\"name\"], \"type\": str(col[\"type\"])} for col in columns\n            ]\n        except Exception as e:\n            schema_overview[table_name] = {\"error\": str(e)}\n\n    return schema_overview", "simple_text2sql.py": "from dotenv import load_dotenv\nfrom langchain_community.utilities.sql_database import SQLDatabase\nfrom langchain_core.messages import AnyMessage, HumanMessage, SystemMessage\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import END, START, StateGraph\nfrom langgraph.graph.message import add_messages\nfrom typing_extensions import Annotated, List, TypedDict\n\nimport sys\nimport os\nfrom pathlib import Path\n\ncurrent_dir = Path(__file__).parent\nif str(current_dir) not in sys.path:\n    sys.path.insert(0, str(current_dir))\n\nfrom prompts import QA_SYSTEM_PROMPT, SQL_SYSTEM_PROMPT\nfrom utils import get_detailed_table_info, get_engine_for_chinook_db\n\nload_dotenv(override=True)\n\n\nclass OverallState(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n    schema: str\n    sql: str\n    records: List[dict]\n\n\nclass InputState(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n\nclass OutputState(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n\ndef generate_sql(llm):\n    def _generate(state: OverallState) -> dict:\n        last_message = state[\"messages\"][-1]\n        prompt = f\"\"\"Generate a SQL query for the following question:\n        Question: {last_message.content}\n        Schema: {get_detailed_table_info()}\n        SQL:\n        \"\"\"\n        sql_query = llm.invoke(\n            [SystemMessage(SQL_SYSTEM_PROMPT)]\n            + state[\"messages\"]\n            + [HumanMessage(prompt)]\n        )\n        sql_query = sql_query.content.replace(\"```sql\", \"\").replace(\"```\", \"\")\n        return {\"sql\": sql_query}\n\n    return _generate\n\n\ndef execute_sql(db):\n    def _execute(state: OverallState) -> dict:\n        records = db.run(state[\"sql\"])\n        return {\"records\": records}\n\n    return _execute\n\n\ndef generate_answer(llm):\n    def _answer(state: OverallState) -> dict:\n        last_message = state[\"messages\"][-1]\n        prompt = f\"Given the question: {last_message.content} and the database results: {state['records']}, provide a concise answer.\"\n        answer = llm.invoke(\n            [SystemMessage(QA_SYSTEM_PROMPT)]\n            + state[\"messages\"]\n            + [HumanMessage(prompt)]\n        )\n        return {\"messages\": [answer]}\n\n    return _answer\n\n\ndef create_agent(llm, db):\n    builder = StateGraph(\n        OverallState, input_schema=InputState, output_schema=OutputState\n    )\n    builder.add_node(\"generate_sql\", generate_sql(llm))\n    builder.add_node(\"execute_sql\", execute_sql(db))\n    builder.add_node(\"generate_answer\", generate_answer(llm))\n    builder.add_edge(START, \"generate_sql\")\n    builder.add_edge(\"generate_sql\", \"execute_sql\")\n    builder.add_edge(\"execute_sql\", \"generate_answer\")\n    builder.add_edge(\"generate_answer\", END)\n    return builder.compile()\n\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\ndb = SQLDatabase(get_engine_for_chinook_db())\nagent = create_agent(llm, db)\n\napp = agent"}}, "outputs": {"reference": "### Documentação Técnica — Projeto Text2SQL\n\n#### Contexto\nO projeto implementa um fluxo Text2SQL usando LangGraph e LangChain para traduzir perguntas em linguagem natural em consultas SQL executáveis em um banco SQLite (Chinook).\n\n#### Objetivos\n- Traduzir perguntas em queries SQL válidas.\n- Executar consultas em tempo real e retornar resultados estruturados.\n- Demonstrar o uso de StateGraph no LangGraph.\n\n#### Tecnologias\n- Python 3.11+\n- LangChain / LangGraph\n- SQLite (Chinook)\n- SQLAlchemy / Requests / Dotenv\n\n#### Fluxo de Dados\n1. Usuário envia uma pergunta.\n2. O agente gera a query SQL.\n3. Executa a query e obtém resultados.\n4. Gera uma resposta textual.\n\n#### Qualidade do Código\n- Estrutura modular.\n- Anotações de tipo e estado.\n- Prompts bem definidos.\n\n#### Pontos Críticos\n- Dependência de schema remoto.\n- Falta de cache e validação intermediária.\n- Possibilidade de SQL injection se usado fora do ambiente controlado."}, "metadata": {"project": "text2sql", "version": "v1"}}
